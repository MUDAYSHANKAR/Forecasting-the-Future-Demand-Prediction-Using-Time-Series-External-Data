!pip install prophet xgboost pmdarima -q

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from prophet import Prophet
import xgboost as xgb
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.model_selection import train_test_split

plt.style.use('seaborn-v0_8-whitegrid')
print("Libraries imported successfully.")

print("\n--- Simulating Realistic Sales Data ---")

date_range = pd.date_range(start='2021-01-01', end='2023-12-31', freq='D')
n_days = len(date_range)

trend = np.linspace(start=100, stop=250, num=n_days)
yearly_seasonality = 25 * np.sin(2 * np.pi * (date_range.dayofyear / 365.25 - 0.2))
weekly_seasonality = 15 * (date_range.dayofweek >= 5)
temp_base = 15
temp_amplitude = 10
temperature = temp_base + temp_amplitude * np.sin(2 * np.pi * (date_range.dayofyear / 365.25 - 0.25)) + np.random.normal(0, 2, n_days)
temperature_effect = 2 * np.maximum(0, temperature - 10)
holidays_list = ['2021-07-04', '2022-07-04', '2023-07-04', '2021-05-31', '2022-05-30', '2023-05-29']
holiday_effect = np.array([50 if str(d.date()) in holidays_list else 0 for d in date_range])
noise = np.random.normal(0, 10, n_days)
sales = trend + yearly_seasonality + weekly_seasonality + temperature_effect + holiday_effect + noise
sales = np.maximum(0, sales)

df = pd.DataFrame({
    'date': date_range,
    'sales': sales,
    'temperature': temperature,
    'is_holiday': (holiday_effect > 0).astype(int),
    'is_weekend': (date_range.dayofweek >= 5).astype(int)
})

print("Sample of the generated data:")
print(df.head())
print("\nData simulation complete.")

print("\n--- Performing Exploratory Data Analysis ---")

df.plot(x='date', y='sales', figsize=(15, 6), title='Simulated Daily Ice Cream Sales')
plt.ylabel('Units Sold')
plt.show()

fig, axes = plt.subplots(1, 2, figsize=(15, 5))
sns.scatterplot(data=df, x='temperature', y='sales', ax=axes[0], alpha=0.5)
axes[0].set_title('Sales vs. Temperature')
sns.boxplot(data=df, x='is_holiday', y='sales', ax=axes[1])
axes[1].set_title('Sales on Holidays vs. Non-Holidays')
axes[1].set_xticklabels(['Non-Holiday', 'Holiday'])
plt.tight_layout()
plt.show()

print("\n--- Preparing Data for Modeling ---")

test_period_start = '2023-10-01'
train_df = df[df['date'] < test_period_start].copy()
test_df = df[df['date'] >= test_period_start].copy()

print(f"Training data from {train_df['date'].min().date()} to {train_df['date'].max().date()}")
print(f"Testing data from {test_df['date'].min().date()} to {test_df['date'].max().date()}")

print("\n--- STAGE 1: Forecasting with Prophet to capture Trend, Seasonality, and Holidays ---")

prophet_train_df = train_df.rename(columns={'date': 'ds', 'sales': 'y'})
holidays_df = pd.DataFrame({
    'holiday': 'major_holiday',
    'ds': pd.to_datetime(holidays_list),
    'lower_window': 0,
    'upper_window': 0,
})

m_prophet = Prophet(
    yearly_seasonality=True,
    weekly_seasonality=True,
    daily_seasonality=False,
    holidays=holidays_df
)
m_prophet.add_regressor('temperature')
m_prophet.add_regressor('is_weekend')
m_prophet.fit(prophet_train_df)

prophet_train_forecast = m_prophet.predict(prophet_train_df)
train_df['prophet_forecast'] = prophet_train_forecast['yhat'].values
train_df['residuals'] = train_df['sales'] - train_df['prophet_forecast']

print("Prophet model trained. Residuals calculated.")

print("\n--- STAGE 2: Training XGBoost to Predict Residuals using External Features ---")

features = ['temperature', 'is_weekend']
target = 'residuals'
X_train_xgb = train_df[features]
y_train_xgb = train_df[target]

m_xgb = xgb.XGBRegressor(
    objective='reg:squarederror',
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=3,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    early_stopping_rounds=10
)
X_train_part, X_val_part, y_train_part, y_val_part = train_test_split(X_train_xgb, y_train_xgb, test_size=0.1, random_state=42)

m_xgb.fit(
    X_train_part, y_train_part,
    eval_set=[(X_val_part, y_val_part)],
    verbose=False
)

print("XGBoost model trained to predict residuals.")

print("\n--- Generating Final Hybrid Forecast on the Test Set ---")

future_df = test_df[['date', 'temperature', 'is_weekend']].rename(columns={'date': 'ds'})
prophet_test_forecast = m_prophet.predict(future_df)
test_df['prophet_forecast'] = prophet_test_forecast['yhat'].values

X_test_xgb = test_df[features]
xgb_residuals_forecast = m_xgb.predict(X_test_xgb)
test_df['xgb_residuals_forecast'] = xgb_residuals_forecast

test_df['hybrid_forecast'] = test_df['prophet_forecast'] + test_df['xgb_residuals_forecast']

print("Forecast generation complete. Sample of test set predictions:")
print(test_df[['date', 'sales', 'prophet_forecast', 'hybrid_forecast']].head())

print("\n--- Evaluating Forecast Performance ---")

actuals = test_df['sales']
prophet_only_preds = test_df['prophet_forecast']
hybrid_preds = test_df['hybrid_forecast']

mae_prophet = mean_absolute_error(actuals, prophet_only_preds)
rmse_prophet = np.sqrt(mean_squared_error(actuals, prophet_only_preds))

mae_hybrid = mean_absolute_error(actuals, hybrid_preds)
rmse_hybrid = np.sqrt(mean_squared_error(actuals, hybrid_preds))

print("Evaluation on the Test Set:")
print(f"Prophet-Only MAE: {mae_prophet:.2f}")
print(f"Prophet-Only RMSE: {rmse_prophet:.2f}")
print("-" * 30)
print(f"Hybrid (Prophet+XGBoost) MAE: {mae_hybrid:.2f} ({(mae_prophet-mae_hybrid)/mae_prophet:.2%} improvement)")
print(f"Hybrid (Prophet+XGBoost) RMSE: {rmse_hybrid:.2f} ({(rmse_prophet-rmse_hybrid)/rmse_prophet:.2%} improvement)")

plt.figure(figsize=(15, 7))
plt.plot(test_df['date'], test_df['sales'], label='Actual Sales', color='black', marker='.', linestyle='None')
plt.plot(test_df['date'], test_df['prophet_forecast'], label='Prophet-Only Forecast', color='blue', linestyle='--')
plt.plot(test_df['date'], test_df['hybrid_forecast'], label='Hybrid (Prophet+XGBoost) Forecast', color='red')
plt.title('Forecast vs. Actuals on Test Set')
plt.xlabel('Date')
plt.ylabel('Units Sold')
plt.legend()
plt.show()

print("""
--- Discussion & Further Steps ---

This notebook demonstrates a powerful hybrid forecasting technique.

Key Takeaways:
1.  Decomposition is Key: Prophet successfully modeled the main trend, seasonalities, 
    and holiday effects, providing a strong baseline forecast.
2.  Hybrid Models Add Value: XGBoost was able to learn the complex, non-linear 
    patterns in the residuals that Prophet's linear regressors missed. This resulted 
    in a more accurate final forecast, as shown by the lower MAE and RMSE scores.
3.  Feature Engineering is Crucial: The quality of the external features (temperature, 
    holidays, weekends) directly impacts the model's performance. In a real-world 
    scenario, you would also consider:
    - Lag features (e.g., sales from the previous day/week).
    - Rolling window statistics (e.g., 7-day average temperature).
    - Other external data (e.g., promotions, competitor pricing, economic indicators).

Alternatives and Next Steps:
- ARIMA/SARIMAX: Instead of Prophet, you could use a SARIMAX model from `statsmodels` 
  or `pmdarima.auto_arima` for Stage 1. SARIMAX is statistically more rigorous but can 
  be more complex to tune, especially with multiple seasonalities and regressors.
- Hyperparameter Tuning: Both Prophet and XGBoost have many parameters that can be 
  tuned (e.g., using GridSearchCV or Optuna) for even better performance.
- Probabilistic Forecasting: Instead of just a single point forecast, you could 
  predict a range of possible outcomes (prediction intervals) to quantify uncertainty.
""")
